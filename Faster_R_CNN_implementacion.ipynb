{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoSimon22/vision_artificial/blob/main/Faster_R_CNN_implementacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGaeq4ADgft2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.datasets import CocoDetection\n",
        "from torchvision.transforms import functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"lX9sE2RPQOCv2R7cn0io\")\n",
        "project = rf.workspace(\"jota22\").project(\"am_boundingbox\")\n",
        "version = project.version(14)\n",
        "dataset = version.download(\"coco\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "R3ku5MyAJ9Ut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf630897-4214-47fd-81a6-ded31009008d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "class CocoTransform:\n",
        "    def __call__(self, image, target):\n",
        "        image = F.to_tensor(image)  # Convert PIL image to tensor\n",
        "        return image, target"
      ],
      "metadata": {
        "id": "870v0WUDg-x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "def get_coco_dataset(img_dir, ann_file):\n",
        "    return CocoDetection(\n",
        "        root=img_dir,\n",
        "        annFile=ann_file,\n",
        "        transforms=CocoTransform()\n",
        "    )\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = get_coco_dataset(\n",
        "    img_dir=\"/content/AM_BoundingBox-14/train\",\n",
        "    ann_file=\"/content/AM_BoundingBox-14/train/_annotations.coco.json\"\n",
        ")\n",
        "\n",
        "\n",
        "val_dataset = get_coco_dataset(\n",
        "    img_dir=\"/content/AM_BoundingBox-14/valid\",\n",
        "    ann_file=\"/content/AM_BoundingBox-14/valid/_annotations.coco.json\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SUiJysJhB2D",
        "outputId": "c918204a-8adb-44ad-ee13-f59cb7b63528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Faster R-CNN with ResNet-50 backbone\n",
        "def get_model(num_classes):\n",
        "    # Load pre-trained Faster R-CNN\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "    # Get the number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "    # Replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "W6HeavRto22C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "num_classes = 2 # background + def\n",
        "model = get_model(num_classes)"
      ],
      "metadata": {
        "id": "c8kVDOHko-mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and learning rate scheduler\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
      ],
      "metadata": {
        "id": "8aiBeYNPpF_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
        "    model.train()\n",
        "    for images, targets in data_loader:\n",
        "        # Move images to the device\n",
        "        images = [img.to(device) for img in images]\n",
        "\n",
        "        # Validate and process targets\n",
        "        processed_targets = []\n",
        "        valid_images = []\n",
        "        for i, target in enumerate(targets):\n",
        "            boxes = []\n",
        "            labels = []\n",
        "            for obj in target:\n",
        "                # Extract bbox\n",
        "                bbox = obj[\"bbox\"]  # Format: [x, y, width, height]\n",
        "                x, y, w, h = bbox\n",
        "\n",
        "                # Ensure the width and height are positive\n",
        "                if w > 0 and h > 0:\n",
        "                    boxes.append([x, y, x + w, y + h])  # Convert to [x_min, y_min, x_max, y_max]\n",
        "                    labels.append(obj[\"category_id\"])\n",
        "\n",
        "            # Only process if there are valid boxes\n",
        "            if boxes:\n",
        "                processed_target = {\n",
        "                    \"boxes\": torch.tensor(boxes, dtype=torch.float32).to(device),\n",
        "                    \"labels\": torch.tensor(labels, dtype=torch.int64).to(device),\n",
        "                }\n",
        "                processed_targets.append(processed_target)\n",
        "                valid_images.append(images[i])  # Add only valid images\n",
        "\n",
        "        # Skip iteration if no valid targets\n",
        "        if not processed_targets:\n",
        "            continue\n",
        "\n",
        "        # Ensure images and targets are aligned\n",
        "        images = valid_images\n",
        "\n",
        "        # Forward pass\n",
        "        loss_dict = model(images, processed_targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch}] Loss: {losses.item():.4f}\")"
      ],
      "metadata": {
        "id": "YThPDcQUpQMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 150\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    # Save the model's state dictionary every 10 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "        model_path = f\"fasterrcnn_resnet50_epoch_{epoch + 1}.pth\"\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f\"‚úÖ Model saved: {model_path}\")\n"
      ],
      "metadata": {
        "id": "DGP1pCn5pbx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MEJORADO: Evaluar todas las im√°genes del conjunto de validaci√≥n y visualizar ---\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CocoDetection\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "\n",
        "# --- CONFIGURACI√ìN ---\n",
        "num_classes = 2  # 1 clase + fondo\n",
        "model_path = \"/content/fasterrcnn_resnet50_epoch_150.pth\"\n",
        "img_dir = \"/content/AM_BoundingBox-14/test\"  # <-- Cambia esto si es necesario\n",
        "ann_file = \"/content/AM_BoundingBox-14/test/_annotations.coco.json\"\n",
        "\n",
        "# --- CARGAR MODELO ---\n",
        "def get_model(num_classes):\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = get_model(num_classes)\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# --- COCO DATASET & LOADER ---\n",
        "def get_transform():\n",
        "    return transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "def get_coco_dataset(img_dir, ann_file):\n",
        "    return CocoDetection(root=img_dir, annFile=ann_file, transform=get_transform())\n",
        "\n",
        "dataset = get_coco_dataset(img_dir, ann_file)\n",
        "val_loader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "# --- FUNCIONES DE DIBUJO ---\n",
        "COCO_CLASSES = {0: \"background\", 1: \"def\"}\n",
        "\n",
        "def get_class_name(class_id):\n",
        "    return COCO_CLASSES.get(class_id, \"unknown\")\n",
        "\n",
        "def draw_boxes(image, prediction, threshold=0.5):\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    boxes = prediction[\"boxes\"].cpu().numpy()\n",
        "    labels = prediction[\"labels\"].cpu().numpy()\n",
        "    scores = prediction[\"scores\"].cpu().numpy()\n",
        "\n",
        "    for box, label, score in zip(boxes, labels, scores):\n",
        "        if score >= threshold:\n",
        "            x_min, y_min, x_max, y_max = box\n",
        "            draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\", width=2)\n",
        "            draw.text((x_min, y_min), f\"{get_class_name(label)} ({score:.2f})\", fill=\"red\")\n",
        "    return image\n",
        "\n",
        "# --- EVALUAR Y GUARDAR RESULTADOS DE TODAS LAS IM√ÅGENES ---\n",
        "out_dir = \"detections\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, (images, targets) in enumerate(tqdm(val_loader, desc=\"Evaluando\")):\n",
        "        image_tensor = images[0].to(device)\n",
        "        output = model([image_tensor])[0]\n",
        "\n",
        "        # Cargar imagen original para visualizar\n",
        "        image_path = dataset.ids[idx]\n",
        "        image_file = dataset.coco.loadImgs(image_path)[0]['file_name']\n",
        "        image = Image.open(os.path.join(img_dir, image_file)).convert(\"RGB\")\n",
        "\n",
        "        # Dibujar predicciones\n",
        "        result_img = draw_boxes(image.copy(), output)\n",
        "\n",
        "        # Guardar\n",
        "        result_img.save(os.path.join(out_dir, f\"prediction_{idx+1}.jpg\"))"
      ],
      "metadata": {
        "id": "M4FSX1fJ9m5j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "43ce2303-4a27-4cbd-c0d0-e727cd9c4a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/fasterrcnn_resnet50_epoch_150.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-43f3c92bfc2f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/fasterrcnn_resnet50_epoch_150.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FUNCI√ìN PARA EVALUAR UN MODELO SOBRE TODO EL DATASET Y DEVOLVER M√âTRICAS ---\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "import json\n",
        "import os\n",
        "from PIL import Image, ImageDraw\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def evaluate_model(model, val_loader, annotations_path, output_json=\"predictions.json\", device=\"cuda\"):\n",
        "    model.eval()\n",
        "    device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    results = []\n",
        "    total_box_loss = 0.0\n",
        "    total_cls_loss = 0.0\n",
        "    n_batches = 0\n",
        "\n",
        "    # Recorrer dataset de validaci√≥n\n",
        "    with torch.no_grad():\n",
        "        for images, targets in tqdm(val_loader, desc=\"Evaluando modelo\"):\n",
        "            images = [img.to(device) for img in images]\n",
        "            new_targets = []\n",
        "            for t in targets:\n",
        "                if isinstance(t, list) and isinstance(t[0], dict):\n",
        "                    new_targets.append({k: v.to(device) if torch.is_tensor(v) else v for k, v in t[0].items()})\n",
        "                elif isinstance(t, dict):\n",
        "                  # Create a 'boxes' key with the 'bbox' values\n",
        "                    t['boxes'] = torch.tensor(t['bbox'], dtype=torch.float32).to(device)  # Assuming bbox is already a list\n",
        "                    new_targets.append({k: v.to(device) if torch.is_tensor(v) else v for k, v in t.items()})\n",
        "                else:\n",
        "                    raise TypeError(\"Formato de target no reconocido: se esperaba lista de dicts o dict\")\n",
        "\n",
        "            targets = new_targets\n",
        "\n",
        "            # Calcular p√©rdidas (modo train necesario)\n",
        "            model.train()\n",
        "            loss_dict = model(images, targets)\n",
        "            total_box_loss += loss_dict['loss_box_reg'].item()\n",
        "            total_cls_loss += loss_dict['loss_classifier'].item()\n",
        "            model.eval()\n",
        "\n",
        "            outputs = model(images)\n",
        "\n",
        "            for i in range(len(outputs)):\n",
        "                image_id = targets[i][\"image_id\"].item()\n",
        "                boxes = outputs[i][\"boxes\"].cpu().numpy()\n",
        "                scores = outputs[i][\"scores\"].cpu().numpy()\n",
        "                labels = outputs[i][\"labels\"].cpu().numpy()\n",
        "\n",
        "                for box, score, label in zip(boxes, scores, labels):\n",
        "                    x1, y1, x2, y2 = box\n",
        "                    results.append({\n",
        "                        \"image_id\": image_id,\n",
        "                        \"category_id\": int(label),\n",
        "                        \"bbox\": [x1, y1, x2 - x1, y2 - y1],\n",
        "                        \"score\": float(score)\n",
        "                    })\n",
        "\n",
        "            n_batches += 1\n",
        "\n",
        "    # Guardar predicciones\n",
        "    with open(output_json, \"w\") as f:\n",
        "        json.dump(results, f)\n",
        "\n",
        "    # Evaluar con COCO\n",
        "    coco_gt = COCO(annotations_path)\n",
        "    coco_dt = coco_gt.loadRes(output_json)\n",
        "    coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "    coco_eval.evaluate()\n",
        "    coco_eval.accumulate()\n",
        "    coco_eval.summarize()\n",
        "\n",
        "    return {\n",
        "        \"map\": coco_eval.stats[0],\n",
        "        \"ap50\": coco_eval.stats[1],\n",
        "        \"recall\": coco_eval.stats[8],\n",
        "        \"box_loss\": total_box_loss / n_batches,\n",
        "        \"cls_loss\": total_cls_loss / n_batches\n",
        "    }\n"
      ],
      "metadata": {
        "id": "ziNyLTG377Jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- COMPARAR VARIOS MODELOS .PTH ---\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "def compare_models(model_paths, model, val_loader, annotations_path, device=\"cuda\"):\n",
        "    resultados = []\n",
        "    for path in model_paths:\n",
        "        model.load_state_dict(torch.load(path, map_location=device))\n",
        "        print(f\"\\nEvaluando modelo: {path}\")\n",
        "        metrics = evaluate_model(model, val_loader, annotations_path, output_json=\"predictions_temp.json\", device=device)\n",
        "        resultados.append({\n",
        "            \"modelo\": os.path.basename(path),\n",
        "            \"mAP@[.5:.95]\": metrics[\"map\"],\n",
        "            \"AP50\": metrics[\"ap50\"],\n",
        "            \"Recall\": metrics[\"recall\"],\n",
        "            \"Box Loss\": metrics[\"box_loss\"],\n",
        "            \"Cls Loss\": metrics[\"cls_loss\"]\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(resultados)\n",
        "    df_ordenado = df.sort_values(by=\"mAP@[.5:.95]\", ascending=False)\n",
        "    print(\"\\nüìä Comparaci√≥n de modelos:\")\n",
        "    print(df_ordenado.to_string(index=False))\n",
        "\n",
        "    # --- GRAFICAR RESULTADOS ---\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(df_ordenado['modelo'], df_ordenado['mAP@[.5:.95]'], label='mAP@[.5:.95]', marker='o')\n",
        "    plt.plot(df_ordenado['modelo'], df_ordenado['AP50'], label='AP50', marker='x')\n",
        "    plt.plot(df_ordenado['modelo'], df_ordenado['Recall'], label='Recall', marker='s')\n",
        "    plt.xlabel(\"Modelo (.pth)\")\n",
        "    plt.ylabel(\"M√©trica\")\n",
        "    plt.title(\"Comparaci√≥n de m√©tricas entre modelos\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --- GUARDAR RESULTADOS EN CSV ---\n",
        "    df_ordenado.to_csv(\"resultados_comparacion_modelos.csv\", index=False)\n",
        "    print(\"\\n‚úÖ Resultados exportados a 'resultados_comparacion_modelos.csv'\")\n",
        "\n",
        "    return df_ordenado\n",
        "\n",
        "\n",
        "# --- EJECUCI√ìN PRINCIPAL ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Lista de modelos a comparar\n",
        "    model_paths = [\n",
        "        \"fasterrcnn_resnet50_epoch_105.pth\",\n",
        "        \"fasterrcnn_resnet50_epoch_120.pth\",\n",
        "        \"fasterrcnn_resnet50_epoch_135.pth\"\n",
        "    ]\n",
        "\n",
        "    # Crear modelo base\n",
        "    def get_model(num_classes):\n",
        "        model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "        in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "        return model\n",
        "\n",
        "    model = get_model(num_classes= 2)  # Ajusta seg√∫n tu dataset\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "     # Preparar val_loader\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    val_dataset = CocoDetection(\n",
        "        root=\"/content/AM_BoundingBox-14/valid\",\n",
        "        annFile=\"/content/AM_BoundingBox-14/valid/_annotations.coco.json\",\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "    # Ruta a las anotaciones COCO del conjunto de validaci√≥n\n",
        "    annotations_path = \"/content/AM_BoundingBox-14/valid/_annotations.coco.json\"\n",
        "\n",
        "    # Ejecutar comparaci√≥n\n",
        "    df_resultados = compare_models(model_paths, model, val_loader, annotations_path, device=device)\n"
      ],
      "metadata": {
        "id": "VsQDUG-M79Re",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "a8dac3f2-a943-489f-9faa-15b29716be37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8084c11d0f98>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ajusta seg√∫n tu dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m      \u001b[0;31m# Preparar val_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # --- GUARDAR RESULTADOS EN CSV ---\n",
        "    df_ordenado.to_csv(\"resultados_comparacion_modelos.csv\", index=False)\n",
        "    print(\"\\n‚úÖ Resultados exportados a 'resultados_comparacion_modelos.csv'\")\n",
        "\n",
        "    return df_ordenado"
      ],
      "metadata": {
        "id": "jbjmyhch8vTd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}