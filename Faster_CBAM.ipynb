{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM+u9MJh5NoLcyO494Onmbt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoSimon22/vision_artificial/blob/main/Faster_CBAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìò Faster R-CNN + CBAM con 1 clase (\"def\")\n",
        "Entrenamiento completo con dataset descargado desde Roboflow."
      ],
      "metadata": {
        "id": "N44FR2QBOueM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jebh_1AuNRld",
        "outputId": "9d59b8ca-5568-418c-dec7-7956be06f5f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m143.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision pycocotools opencv-python matplotlib tqdm roboflow -q\n",
        "\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.datasets import CocoDetection\n",
        "from torchvision.transforms import functional as F\n",
        "from torchvision import transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "!pip install pycocotools\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# üîß CBAM M√≥dulo\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.fc(self.avg_pool(x)) + self.fc(self.max_pool(x))) * x\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x_cat = torch.cat([avg_out, max_out], dim=1)\n",
        "        return self.sigmoid(self.conv(x_cat)) * x\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16, kernel_size=7):\n",
        "        super().__init__()\n",
        "        self.ca = ChannelAttention(in_planes, ratio)\n",
        "        self.sa = SpatialAttention(kernel_size)\n",
        "    def forward(self, x):\n",
        "        return self.sa(self.ca(x))\n",
        "\n",
        "# ‚öôÔ∏è Cargar backbone con CBAM insertado correctamente\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
        "import types\n",
        "\n",
        "def insert_cbam_in_layer2(backbone, device):\n",
        "    original_layer2 = backbone.body.layer2\n",
        "    cbam = CBAM(512).to(device)\n",
        "\n",
        "    def new_forward(self, x):\n",
        "        x = original_layer2(x)\n",
        "        x = cbam(x)\n",
        "        return x\n",
        "\n",
        "    backbone.body.layer2.forward = types.MethodType(new_forward, backbone.body.layer2)\n",
        "    return backbone\n",
        "\n",
        "# üì¶ Crea el modelo con CBAM en layer2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "backbone = resnet_fpn_backbone('resnet50', pretrained=True)\n",
        "backbone = insert_cbam_in_layer2(backbone, device)\n",
        "model = FasterRCNN(backbone, num_classes=2)\n",
        "model.to(device)\n",
        "\n",
        "print(\"‚úÖ Modelo Faster R-CNN con CBAM integrado en layer2\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd17ytFANemH",
        "outputId": "942c7435-61bd-4556-8603-5efefd630bf2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'backbone_name' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 233MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo Faster R-CNN con CBAM integrado en layer2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "import torch.nn as nn\n",
        "\n",
        "backbone = resnet_fpn_backbone('resnet50', pretrained=True)\n",
        "backbone.body.layer2 = nn.Sequential(\n",
        "    backbone.body.layer2,\n",
        "    CBAM(512)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9nxmBisNVsp",
        "outputId": "1583b36e-cfe3-455c-831f-c112cc1fdbbb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using 'backbone_name' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FasterRCNN(backbone, num_classes=2)\n",
        "print(\"‚úÖ Modelo con CBAM cargado\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_N6zJgoNtLP",
        "outputId": "487002ba-5b4e-4129-d6fa-4a5bfe3cad57"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo con CBAM cargado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"lX9sE2RPQOCv2R7cn0io\")\n",
        "project = rf.workspace(\"jota22\").project(\"am_boundingbox\")\n",
        "version = project.version(14)\n",
        "dataset = version.download(\"coco\")\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.0005, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR2pLHUJNy_U",
        "outputId": "bf5502cb-cc4d-4ac5-cd62-4705a4ae9799"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.11/dist-packages (1.1.64)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.4.26)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.2.1)\n",
            "Requirement already satisfied: pillow-heif>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.22.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.58.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.2)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for images, targets in data_loader:\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += losses.item()\n",
        "\n",
        "    print(f\"üìò Epoch [{epoch+1}] | Loss: {epoch_loss:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fBFx_qn6N2-p"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CocoDetectionFasterRCNN(CocoDetection):\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = super().__getitem__(idx)\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        for obj in target:\n",
        "            x, y, w, h = obj['bbox']\n",
        "            if w > 0 and h > 0:\n",
        "                boxes.append([x, y, x + w, y + h])\n",
        "                labels.append(obj['category_id'])\n",
        "        if len(boxes) == 0:\n",
        "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            labels = torch.tensor([], dtype=torch.int64)\n",
        "        else:\n",
        "            boxes = torch.tensor(boxes, dtype=torch.float32)\n",
        "            labels = torch.tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        target = {\n",
        "            \"boxes\": boxes,\n",
        "            \"labels\": labels,\n",
        "            \"image_id\": torch.tensor([idx]),\n",
        "            \"area\": (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]),\n",
        "            \"iscrowd\": torch.zeros((len(labels),), dtype=torch.int64)\n",
        "        }\n",
        "        return img, target\n",
        "\n",
        "class SimpleTransform:\n",
        "    def __call__(self, image, target=None):\n",
        "        return T.ToTensor()(image), target\n",
        "\n",
        "def get_coco_dataset(img_dir, ann_file):\n",
        "    return CocoDetectionFasterRCNN(\n",
        "        root=img_dir,\n",
        "        annFile=ann_file,\n",
        "        transforms=SimpleTransform()\n",
        "    )\n",
        "\n",
        "train_dataset = get_coco_dataset(\n",
        "    img_dir=\"/content/AM_BoundingBox-14/train\",\n",
        "    ann_file=\"/content/AM_BoundingBox-14/train/_annotations.coco.json\"\n",
        ")\n",
        "\n",
        "val_dataset = get_coco_dataset(\n",
        "    img_dir=\"/content/AM_BoundingBox-14/valid\",\n",
        "    ann_file=\"/content/AM_BoundingBox-14/valid/_annotations.coco.json\"\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvE8Rpt4OExV",
        "outputId": "043e3945-c81a-4671-c00b-7002117485af"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.20s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0): Bottleneck(\n",
              "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "              (1): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "            )\n",
              "          )\n",
              "          (1): Bottleneck(\n",
              "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Bottleneck(\n",
              "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (3): Bottleneck(\n",
              "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (1): CBAM(\n",
              "          (ca): ChannelAttention(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
              "            (fc): Sequential(\n",
              "              (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): ReLU()\n",
              "              (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            )\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "          (sa): SpatialAttention(\n",
              "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 150\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
        "    lr_scheduler.step()\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "        model_path = f\"fasterrcnn_resnet50_epoch_{epoch + 1}.pth\"\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f\"‚úÖ Model saved: {model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2JhaiSkOT2U",
        "outputId": "f6fae502-522f-4ac3-8954-f17b0fce658e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìò Epoch [1] | Loss: 35.6812\n",
            "üìò Epoch [2] | Loss: 35.6715\n",
            "üìò Epoch [3] | Loss: 35.6869\n",
            "üìò Epoch [4] | Loss: 35.7342\n",
            "üìò Epoch [5] | Loss: 35.6432\n",
            "üìò Epoch [6] | Loss: 35.6836\n",
            "üìò Epoch [7] | Loss: 35.7144\n",
            "üìò Epoch [8] | Loss: 35.7020\n",
            "üìò Epoch [9] | Loss: 35.6646\n",
            "üìò Epoch [10] | Loss: 35.7124\n",
            "üìò Epoch [11] | Loss: 35.6926\n",
            "üìò Epoch [12] | Loss: 35.6798\n",
            "üìò Epoch [13] | Loss: 35.6358\n",
            "üìò Epoch [14] | Loss: 35.7107\n",
            "üìò Epoch [15] | Loss: 35.6733\n",
            "‚úÖ Model saved: fasterrcnn_resnet50_epoch_15.pth\n",
            "üìò Epoch [16] | Loss: 35.6559\n",
            "üìò Epoch [17] | Loss: 35.6570\n",
            "üìò Epoch [18] | Loss: 35.6936\n",
            "üìò Epoch [19] | Loss: 35.6683\n",
            "üìò Epoch [20] | Loss: 35.6808\n",
            "üìò Epoch [21] | Loss: 35.6924\n",
            "üìò Epoch [22] | Loss: 35.6406\n",
            "üìò Epoch [23] | Loss: 35.6729\n",
            "üìò Epoch [24] | Loss: 35.6740\n",
            "üìò Epoch [25] | Loss: 35.6699\n",
            "üìò Epoch [26] | Loss: 35.6384\n",
            "üìò Epoch [27] | Loss: 35.6607\n",
            "üìò Epoch [28] | Loss: 35.6895\n",
            "üìò Epoch [29] | Loss: 35.6609\n",
            "üìò Epoch [30] | Loss: 35.7007\n",
            "‚úÖ Model saved: fasterrcnn_resnet50_epoch_30.pth\n",
            "üìò Epoch [31] | Loss: 35.7333\n",
            "üìò Epoch [32] | Loss: 35.7293\n",
            "üìò Epoch [33] | Loss: 35.6686\n",
            "üìò Epoch [34] | Loss: 35.7159\n",
            "üìò Epoch [35] | Loss: 35.7071\n",
            "üìò Epoch [36] | Loss: 35.6877\n",
            "üìò Epoch [37] | Loss: 35.6736\n",
            "üìò Epoch [38] | Loss: 35.6788\n",
            "üìò Epoch [39] | Loss: 35.7104\n",
            "üìò Epoch [40] | Loss: 35.6777\n",
            "üìò Epoch [41] | Loss: 35.6793\n",
            "üìò Epoch [42] | Loss: 35.6664\n",
            "üìò Epoch [43] | Loss: 35.6852\n",
            "üìò Epoch [44] | Loss: 35.6580\n",
            "üìò Epoch [45] | Loss: 35.6917\n",
            "‚úÖ Model saved: fasterrcnn_resnet50_epoch_45.pth\n",
            "üìò Epoch [46] | Loss: 35.6484\n",
            "üìò Epoch [47] | Loss: 35.6608\n",
            "üìò Epoch [48] | Loss: 35.5608\n",
            "üìò Epoch [49] | Loss: 35.6266\n",
            "üìò Epoch [50] | Loss: 35.7321\n",
            "üìò Epoch [51] | Loss: 35.6936\n",
            "üìò Epoch [52] | Loss: 35.6864\n",
            "üìò Epoch [53] | Loss: 35.6445\n",
            "üìò Epoch [54] | Loss: 35.6494\n",
            "üìò Epoch [55] | Loss: 35.6846\n",
            "üìò Epoch [56] | Loss: 35.6607\n",
            "üìò Epoch [57] | Loss: 35.6670\n",
            "üìò Epoch [58] | Loss: 35.6647\n",
            "üìò Epoch [59] | Loss: 35.6834\n",
            "üìò Epoch [60] | Loss: 35.7147\n",
            "‚úÖ Model saved: fasterrcnn_resnet50_epoch_60.pth\n",
            "üìò Epoch [61] | Loss: 35.7503\n",
            "üìò Epoch [62] | Loss: 35.7005\n",
            "üìò Epoch [63] | Loss: 35.6757\n",
            "üìò Epoch [64] | Loss: 35.6993\n",
            "üìò Epoch [65] | Loss: 35.6386\n",
            "üìò Epoch [66] | Loss: 35.6557\n",
            "üìò Epoch [67] | Loss: 35.7015\n",
            "üìò Epoch [68] | Loss: 35.6942\n",
            "üìò Epoch [69] | Loss: 35.6983\n",
            "üìò Epoch [70] | Loss: 35.6826\n",
            "üìò Epoch [71] | Loss: 35.6990\n",
            "üìò Epoch [72] | Loss: 35.6576\n",
            "üìò Epoch [73] | Loss: 35.6896\n",
            "üìò Epoch [74] | Loss: 35.6519\n",
            "üìò Epoch [75] | Loss: 35.6924\n",
            "‚úÖ Model saved: fasterrcnn_resnet50_epoch_75.pth\n",
            "üìò Epoch [76] | Loss: 35.7036\n",
            "üìò Epoch [77] | Loss: 35.7148\n",
            "üìò Epoch [78] | Loss: 35.6128\n",
            "üìò Epoch [79] | Loss: 35.6603\n",
            "üìò Epoch [80] | Loss: 35.6987\n",
            "üìò Epoch [81] | Loss: 35.6923\n",
            "üìò Epoch [82] | Loss: 35.6556\n",
            "üìò Epoch [83] | Loss: 35.6714\n",
            "üìò Epoch [84] | Loss: 35.6669\n",
            "üìò Epoch [85] | Loss: 35.6440\n",
            "üìò Epoch [86] | Loss: 35.6756\n",
            "üìò Epoch [87] | Loss: 35.6572\n",
            "üìò Epoch [88] | Loss: 35.6659\n",
            "üìò Epoch [89] | Loss: 35.6448\n",
            "üìò Epoch [90] | Loss: 35.6957\n",
            "‚úÖ Model saved: fasterrcnn_resnet50_epoch_90.pth\n",
            "üìò Epoch [91] | Loss: 35.7225\n",
            "üìò Epoch [92] | Loss: 35.6930\n",
            "üìò Epoch [93] | Loss: 35.6267\n",
            "üìò Epoch [94] | Loss: 35.6842\n",
            "üìò Epoch [95] | Loss: 35.7324\n",
            "üìò Epoch [96] | Loss: 35.6110\n",
            "üìò Epoch [97] | Loss: 35.6232\n",
            "üìò Epoch [98] | Loss: 35.6792\n",
            "üìò Epoch [99] | Loss: 35.6576\n",
            "üìò Epoch [100] | Loss: 35.5852\n",
            "üìò Epoch [101] | Loss: 35.6813\n",
            "üìò Epoch [102] | Loss: 35.6993\n",
            "üìò Epoch [103] | Loss: 35.6741\n",
            "üìò Epoch [104] | Loss: 35.7190\n",
            "üìò Epoch [105] | Loss: 35.6948\n",
            "‚úÖ Model saved: fasterrcnn_resnet50_epoch_105.pth\n",
            "üìò Epoch [106] | Loss: 35.6558\n",
            "üìò Epoch [107] | Loss: 35.7039\n",
            "üìò Epoch [108] | Loss: 35.7270\n",
            "üìò Epoch [109] | Loss: 35.7014\n",
            "üìò Epoch [110] | Loss: 35.6789\n",
            "üìò Epoch [111] | Loss: 35.6481\n",
            "üìò Epoch [112] | Loss: 35.6599\n",
            "üìò Epoch [113] | Loss: 35.7010\n",
            "üìò Epoch [114] | Loss: 35.6295\n",
            "üìò Epoch [115] | Loss: 35.6781\n",
            "üìò Epoch [116] | Loss: 35.6523\n",
            "üìò Epoch [117] | Loss: 35.6697\n",
            "üìò Epoch [118] | Loss: 35.6837\n",
            "üìò Epoch [119] | Loss: 35.6350\n",
            "üìò Epoch [120] | Loss: 35.6601\n",
            "‚úÖ Model saved: fasterrcnn_resnet50_epoch_120.pth\n",
            "üìò Epoch [121] | Loss: 35.7197\n",
            "üìò Epoch [122] | Loss: 35.6931\n",
            "üìò Epoch [123] | Loss: 35.6640\n",
            "üìò Epoch [124] | Loss: 35.6432\n",
            "üìò Epoch [125] | Loss: 35.6935\n",
            "üìò Epoch [126] | Loss: 35.6660\n",
            "üìò Epoch [127] | Loss: 35.7073\n",
            "üìò Epoch [128] | Loss: 35.6405\n",
            "üìò Epoch [129] | Loss: 35.6893\n",
            "üìò Epoch [130] | Loss: 35.6936\n",
            "üìò Epoch [131] | Loss: 35.6743\n",
            "üìò Epoch [132] | Loss: 35.6456\n",
            "üìò Epoch [133] | Loss: 35.6470\n",
            "üìò Epoch [134] | Loss: 35.6638\n",
            "üìò Epoch [135] | Loss: 35.6747\n",
            "‚úÖ Model saved: fasterrcnn_resnet50_epoch_135.pth\n",
            "üìò Epoch [136] | Loss: 35.7403\n",
            "üìò Epoch [137] | Loss: 35.7038\n",
            "üìò Epoch [138] | Loss: 35.6901\n",
            "üìò Epoch [139] | Loss: 35.6930\n",
            "üìò Epoch [140] | Loss: 35.6900\n",
            "üìò Epoch [141] | Loss: 35.6961\n",
            "üìò Epoch [142] | Loss: 35.7259\n",
            "üìò Epoch [143] | Loss: 35.6731\n",
            "üìò Epoch [144] | Loss: 35.6849\n",
            "üìò Epoch [145] | Loss: 35.6823\n",
            "üìò Epoch [146] | Loss: 35.6762\n",
            "üìò Epoch [147] | Loss: 35.7110\n",
            "üìò Epoch [148] | Loss: 35.6729\n",
            "üìò Epoch [149] | Loss: 35.7023\n",
            "üìò Epoch [150] | Loss: 35.6501\n",
            "‚úÖ Model saved: fasterrcnn_resnet50_epoch_150.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîç Evaluaci√≥n con pycocotools sobre el conjunto de test\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Cargar dataset de test\n",
        "from torchvision.datasets import CocoDetection\n",
        "\n",
        "test_img_dir = \"/content/AM_BoundingBox-14/test\"\n",
        "test_ann_file = \"/content/AM_BoundingBox-14/test/_annotations.coco.json\"\n",
        "\n",
        "class CocoDetectionTest(CocoDetection):\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = super().__getitem__(idx)\n",
        "        image_id = target[0]['image_id'] if target else idx\n",
        "        return img, image_id\n",
        "\n",
        "test_dataset = CocoDetectionTest(test_img_dir, test_ann_file, transform=T.ToTensor())\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "results = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, image_ids in test_loader:\n",
        "        images = [img.to(device) for img in images]\n",
        "        outputs = model(images)\n",
        "\n",
        "        for output, image_id in zip(outputs, image_ids):\n",
        "            boxes = output['boxes'].cpu().numpy()\n",
        "            scores = output['scores'].cpu().numpy()\n",
        "            labels = output['labels'].cpu().numpy()\n",
        "\n",
        "            for box, score, label in zip(boxes, scores, labels):\n",
        "                x_min, y_min, x_max, y_max = box\n",
        "                results.append({\n",
        "                    \"image_id\": int(image_id),\n",
        "                    \"category_id\": int(label),\n",
        "                    \"bbox\": [float(x_min), float(y_min), float(x_max - x_min), float(y_max - y_min)],\n",
        "                    \"score\": float(score)\n",
        "                })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssGxB5eNOU2g",
        "outputId": "9a7f6999-b30c-4c9b-adb0-6de54a52db5d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar resultados en JSON para COCOeval\n",
        "with open(\"results_coco.json\", \"w\") as f:\n",
        "    json.dump(results, f)\n",
        "\n",
        "coco_gt = COCO(test_ann_file)\n",
        "coco_dt = coco_gt.loadRes(\"results_coco.json\")\n",
        "\n",
        "coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "coco_eval.evaluate()\n",
        "coco_eval.accumulate()\n",
        "coco_eval.summarize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8abQSxtUOjhR",
        "outputId": "d86ebcdd-2623-4223-a402-74bfd9247066"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.74s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
          ]
        }
      ]
    }
  ]
}